---
title: A state-space model to evaluate sports teams
author: ''
date: '2018-04-09'
slug: a-state-space-model-to-evaluate-sports-teams
categories: []
tags:
  - NHL
  - state-space
header:
  caption: ''
  image: ''
---



<p>A few years ago at a statistics conference, <a href="https://www.luc.edu/math/ftfaculty/matthewsgregory.shtml">Greg</a>, <a href="http://www.science.smith.edu/~bbaumer/w/">Ben</a> and I sat down to air a few greviences about our favorite sports. They were upset about baseball, and I was irked about hockey. Why the irritation?</p>
<p>Relative to other popular sports like basketball and football, it seemed to us at the time that the best team was winning less often in baseball and hockey. And as fans wanting skilled teams to be rewarded, it was frustrating to so often have well-constructed teams fall short of titles.</p>
<p>And so we decided to write a paper (pre-print <a href="https://arxiv.org/abs/1701.05976">here</a>), now forthcoming in <em>Annals of Applied Statistics</em>, that extends Glickman and Stern’s <a href="https://homepages.cae.wisc.edu/~dwilson/rsfc/rate/papers/a-state-space-model.pdf">state-space model</a> to make comparisons between the NFL, NHL, NBA and MLB. In this post, I’ll describe the attraction of a state-space model, how to build one yourself (using the 2017-18 NHL season), and use our model estimates to answer a few hockey-specific questions. The entire analysis is reproducible, and you should be able to copy-and-paste your way into replicating the findings below.</p>
<div id="the-role-of-betting-market-data" class="section level2">
<h2>The role of betting market data</h2>
<p>Team quality in sports is not static. Players get hurt, traded, or decide to retire. Managers are fired. Teams rest players, switch starting goalies, rotate a pitching staff, or decide they want to tank. All of these aspects make measuring team strength a bit dicey.</p>
<p>Moreso than wins and losses or point differential, perhaps the best game-level metric of team strength comes not in what happens during the game, but what’s known before the game begins. Indeed, it’s been shown <a href="https://www.jstor.org/stable/2287640">time</a> and <a href="https://statsbylopez.files.wordpress.com/2013/08/jqas-2014-0058.pdf">again</a> that there’s no better way to judge models in sports than to compare to betting market data. Prior to each contest, betting markets put out probabilities associated with each team winning. The reason this data is so accurate is that it takes into account all of the factors above – injuries, opponent strength, line-ups, tanking, etc. And so as the saying goes – ``if you can’t beat em, use their data to develop a state-space model.’’ Or something like that.</p>
<p>Assume home team <span class="math inline">\(i\)</span> (listed at -130 on the money line) is playing away team <span class="math inline">\(j\)</span> (+110). Punters backing <span class="math inline">\(i\)</span> believe that squad has better than a <span class="math inline">\(\frac{130}{230} = 56.5\%\)</span> chance of winning, while betters on team <span class="math inline">\(j\)</span> assume it has at least a <span class="math inline">\(\frac{100}{210} = 47.6\%\)</span> probability of winning. Accounting for the vig – which markets use to ensure a long-term profit – team <span class="math inline">\(i\)</span> can be assumed to have a <span class="math inline">\(54.3\%\)</span> chance of beating <span class="math inline">\(j\)</span>.</p>
<p>Let’s take a look at what this data could look like. Here’s a sample of the 2017-18 NHL season (thanks to <a href="https://twitter.com/pucktails">Andy</a> for sharing his spreadsheet, which loads using the <code>gsheet</code> package).</p>
<pre class="r"><code>library(tidyverse) 
library(rjags)
library(gsheet)
library(lubridate)
library(stringr)
library(knitr)

logit &lt;- function(p) { 
  out &lt;- log(p/(1 - p))
  return(out)
}

## Read in data from google sheets
urlA &lt;- &quot;https://docs.google.com/spreadsheets/d/1Hsmqphn9kGqWa88aYnimQxOvdV7ulv_jeIj0SYeBr3s/edit?usp=sharing&quot;
nhl1718 &lt;- gsheet2tbl(urlA)

## Improve the date format
nhl1718 &lt;- nhl1718 %&gt;% separate(date, c(&quot;day&quot;, &quot;month&quot;), &quot;-&quot;) %&gt;% 
  mutate(date = ymd(paste(year, month, day)))

min.day &lt;- min(nhl1718$date)
nhl1718 &lt;- nhl1718 %&gt;%
  mutate(day = date - min.day, week = as.numeric(floor(day/7) + 1))

tab.out &lt;- head(nhl1718, 4) %&gt;% select(date, home, away, p_home)
kable(tab.out)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">date</th>
<th align="left">home</th>
<th align="left">away</th>
<th align="right">p_home</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2017-10-04</td>
<td align="left">Winnipeg Jets</td>
<td align="left">Toronto Maple Leafs</td>
<td align="right">0.5284</td>
</tr>
<tr class="even">
<td align="left">2017-10-04</td>
<td align="left">Pittsburgh Penguins</td>
<td align="left">St. Louis Blues</td>
<td align="right">0.6275</td>
</tr>
<tr class="odd">
<td align="left">2017-10-04</td>
<td align="left">Edmonton Oilers</td>
<td align="left">Calgary Flames</td>
<td align="right">0.5900</td>
</tr>
<tr class="even">
<td align="left">2017-10-04</td>
<td align="left">San Jose Sharks</td>
<td align="left">Philadelphia Flyers</td>
<td align="right">0.5810</td>
</tr>
</tbody>
</table>
<p>In the first four games of the year, Winnipeg, Pittsburgh, Edmonton, and San Jose were all favorites to some degree, with Pittsburgh the most plausible winner.</p>
</div>
<div id="building-a-state-space-model" class="section level2">
<h2>Building a state-space model</h2>
<p>Let <span class="math inline">\(y_{i,j,w} = \text{logit}(p_{i,j,w})\)</span> (in our data, this is called <code>p_home</code>) be the log-odds of the observed betting market probability in a game played between <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> during week <span class="math inline">\(w\)</span>. We take the <code>logit</code> transform of each probability, which more closely aligns our outcomes with a normal distribution.</p>
<p>We formally assume that:</p>
<p><span class="math display">\[
\text{E}[\text{logit}(p_{i,j,w})] = \theta_{i,w} - \theta_{j,w} + \alpha,
\]</span></p>
<p>where <span class="math inline">\(\theta_{i,w}\)</span> and <span class="math inline">\(\theta_{j,w}\)</span> reflect the corresponding team strengths of <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> during week <span class="math inline">\(w\)</span>, and <span class="math inline">\(\alpha\)</span> is the home advantage parameter. You’ll note that as <span class="math inline">\(\theta_{i,w}\)</span> goes up, so to does team <span class="math inline">\(i\)</span>’s probability of winning; followers of paired comparison comparison models will recognize this formulation as identical to Bradley-Terry.</p>
<p>A state-space model assumes that the team strength estimates (<span class="math inline">\(\theta_{i,w}\)</span>, <span class="math inline">\(\theta_{j,w}\)</span>, etc.) evolve over time, with team <span class="math inline">\(i\)</span>’s strength at week <span class="math inline">\(w\)</span> a function of both how good it was last week (<span class="math inline">\(\theta_{i,(w-1)}\)</span>), as well as some prior noise. This is perfect for sports data – teams generally evolve slowly, and the best predictor of how good any given team is at a given time point is likely closely related to how good it was at the time just prior.</p>
<p>Formally, we assume that for any given team <span class="math inline">\(i\)</span>,</p>
<p><span class="math display">\[
\theta_{i,w} \sim N(\gamma\theta_{i,(w-1)},\tau_w^2),
\]</span></p>
<p>which imposes a first-order auto-regressive process to team strength (denoted by <span class="math inline">\(\gamma\)</span>). Above, <span class="math inline">\(\tau_w^2\)</span> corresponds to week-level uncertainty in the evolution of team strength. In the long run, we assume <span class="math inline">\(\gamma &lt; 1\)</span>, which prevents team strengths from exploding, and corresponds to the fact that, eventually, the best and worst teams in pro-sports will revert towards the league average.</p>
<p>Here’s how we can built the model above, where we use the <code>rjags</code> package in R to do some Bayesian inference using Gibbs sampling. First, we define our model inputs using outcome <span class="math inline">\(y\)</span>, week <span class="math inline">\(w\)</span>, and design matrix <span class="math inline">\(x\)</span>. For an <span class="math inline">\(n\)</span>-game season played between <span class="math inline">\(T\)</span>-number of teams, <span class="math inline">\(x\)</span> corresponds to an <span class="math inline">\(n\)</span> x <span class="math inline">\(T\)</span> matrix, where each row contains exactly one 1 (for the home team) and one -1 (for the away team).</p>
<pre class="r"><code>y &lt;- logit(nhl1718$p_home)
w &lt;- nhl1718$week

#create a design matrix 
Teams &lt;- sort(as.character(unique(c(as.character(nhl1718$home)))))

#Defining the number of things
nTeams &lt;- length(Teams)
nWeeks &lt;- max(nhl1718$week)
n &lt;- nrow(nhl1718)

#Defining the design matrix
x &lt;- matrix(0, nrow = dim(nhl1718)[1], ncol = length(Teams))
for (i in 1:dim(nhl1718)[1]) {
  x[i, which(as.character(nhl1718[i,&quot;home&quot;]) == Teams)] &lt;- (1)
  x[i, which(as.character(nhl1718[i,&quot;away&quot;]) == Teams)] &lt;- (-1)
} </code></pre>
<p>As an example, row 1, a game between home team Winnipeg (the 31st NHL team, alphabetically) and away team Toronto (27th), has a <code>1</code> in the 31st column and a <code>-1</code> in the 27th column, with the rest of the entries equal to zero.</p>
<p>Next, our Bayesian approach requires prior distributions on the parameters of interest. I’m happy to answer specific questions if you’d like, but the BUGS code below corresponds to the models above, along with some additional variance parameters that use vague priors. The <code>rjags</code> package is a bit outdated, but here’s <a href="http://www.jkarreth.net/files/bayes-cph_Tutorial-JAGS.pdf">one resource</a> where you can learn more.</p>
<p>Here’s what the BUGS code looks like:</p>
<pre class="r"><code>model.string &lt;-&quot;
  model { 
for (i in 1:n) {
  y[i] ~ dnorm(mu[i], tauGame)
  mu[i] &lt;- alpha + inprod(theta[w[i],],x[i,])
}
for (j in 1:nTeams){
  theta[1,j] ~ dnorm(0, tauSeason)
}
for (www in 2:nWeeks) {  
  for (j in 1:nTeams) {
    theta[www,j] ~ dnorm(gammaWeek*theta[www-1,j], tauWeek)
  }
}
alpha ~ dnorm(0,0.0001)
tauGame ~ dunif(0,1000) #uncertainty in outcome for each game
tauWeek ~ dunif(0,1000) 
tauSeason ~ dunif(0,1000) #variance parameter for the first week of the season
gammaWeek ~ dunif(0,1.5)
}
&quot;
model.spec&lt;-textConnection(model.string)</code></pre>
<p>Now we’re ready to fit the model. In this example, I used 3 chains, 1000 posterior draws, and a thin of 5, which yields 3 sets of 200 draws for each parameter. The model converges quickly, otherwise we’d want to increase the number of draws at each step.</p>
<pre class="r"><code>library(rjags)
n.chains &lt;- 3 
n.adapt &lt;- n.update &lt;- n.draws &lt;- 1000

posteriorDraws = c(&#39;alpha&#39;,&#39;theta&#39;)
thin &lt;- 5
jags &lt;- jags.model(model.spec,
                   data = list(&#39;y&#39; = y,&#39;x&#39; = x, &#39;w&#39; = w, &#39;n&#39; = n,&#39;nTeams&#39; = nTeams,&#39;nWeeks&#39; = nWeeks), 
                   n.chains = n.chains, n.adapt = n.adapt)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 1271
##    Unobserved stochastic nodes: 842
##    Total graph size: 47475
## 
## Initializing model</code></pre>
<pre class="r"><code>update(jags, n.update)
z &lt;- jags.samples(jags, posteriorDraws, n.draws, thin = thin)</code></pre>
</div>
<div id="examining-model-output" class="section level2">
<h2>Examining model output</h2>
<p>Our output file <code>z</code> contains information related to each of the parameters we were interested in. In this case, we have <code>z$alpha</code> (home advantage) and <code>z$theta</code> (team strengths), which have dimensions shown below.</p>
<pre class="r"><code>dim(z$alpha)</code></pre>
<pre><code>##           iteration     chain 
##         1       200         3</code></pre>
<pre class="r"><code>dim(z$theta)</code></pre>
<pre><code>##                     iteration     chain 
##        27        31       200         3</code></pre>
<p>It’s generally a good idea to start a Bayesian analysis by assessing convergence – we do this extensively in our <a href="https://arxiv.org/abs/1701.05976">paper</a> – but here’s one trace plot of <code>alpha</code>, which shows that it’s generally well-behaved. Note the y-axis scale – given that our model uses log-odds as an outcome, each of our coefficients are likewise on a log-odds scale. Each color reflects one of the three chains from our Gibbs sampler.</p>
<pre class="r"><code>colours &lt;- c(&quot;#7fc97f&quot;, &quot;#beaed4&quot;, &quot;#fdc086&quot;)
hfas &lt;- data.frame(round(z$alpha[,,], 3))  %&gt;% mutate(draw = 1:n())
hfas %&gt;% ggplot(aes(draw, X1)) +
  geom_line(colour = colours[1]) + 
  geom_line(data = hfas, aes(draw, X2), colour = colours[2]) + 
  geom_line(data = hfas, aes(draw, X3), colour = colours[3]) + 
  xlab(&quot;Draw&quot;) + 
  ggtitle(&quot;Home advantage (logit scale)&quot;) + 
  ylab(&quot;&quot;) + 
  theme_bw()</code></pre>
<p><img src="/post/2018-04-09-a-state-space-model-to-evaluate-sports-team-performance_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The posterior distrbution of <span class="math inline">\(\alpha\)</span> is centered at about 0.208. This suggests that home teams, when playing a similarly talented opponent, have about a <span class="math inline">\(\frac{e^{0.208.}}{1 + e^{0.208}} = 55\%\)</span> chance of winning. For those scoring at home, the NHL has the third best home advantage among the four sports we analyzed.</p>
<p>Next, we examine team strengths.</p>
<p>In the code below, I averaged each team strength over each week of the NHL season, and highlight the Vegas Golden Knights, a team that rose from the bottom of the league towards the top.</p>
<p>As with the home advantage parameter, the y-axis reflects a log-odds scale. In this case, a coefficient of 0.5 reflects that a team has an <span class="math inline">\(\frac{e^{0.5}}{1+e^{0.5}} = 62\%\)</span> chance of beating a league average team at a neutral site.</p>
<pre class="r"><code>avgs &lt;- apply(z$theta, c(1,2), mean)
dims &lt;- dim(avgs)
names(dims) &lt;- c(&quot;nweeks&quot;, &quot;nteams&quot;)
df.beta &lt;- data.frame(
    theta = as.vector(avgs),
    week = rep(1:dims[&quot;nweeks&quot;]), 
    team_id = rep(Teams, each =dims[&quot;nweeks&quot;]) )
vegas &lt;- filter(df.beta, team_id == &quot;Vegas Golden Knights&quot;)

ggplot(df.beta, aes(week, theta, group = team_id)) + 
  geom_point(colour = &quot;grey&quot;) + 
  geom_line(colour = &quot;grey&quot;) + 
  geom_line(data = vegas, colour = &quot;#b4975a&quot;) + 
  geom_point(data = vegas, colour = &quot;#b4975a&quot;) + 
  ggtitle(&quot;NHL team strengths by week of season, 2017-18&quot;) + 
  ylab(&quot;theta (log-odds scale)&quot;) + 
  ylim(c(-0.56, 0.56)) + 
  annotate(&quot;text&quot;,x = 5, y = -0.4, label = &quot;Vegas&quot;, colour = &quot;gold4&quot;, size = 5) + 
  xlab(&quot;Week&quot;) + theme_bw(14)</code></pre>
<p><img src="/post/2018-04-09-a-state-space-model-to-evaluate-sports-team-performance_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Vegas had a pretty incredible season.</p>
<p>Of course, it’d be nice to see every team. Next, we use the <code>teamcolors</code> package <a href="https://github.com/beanumber/teamcolors">(link)</a> and a bit of <code>ggplot2</code> wizardry to facet each NHL division in order to observe each team.</p>
<pre class="r"><code>library(teamcolors)
teamcolors1 &lt;- teamcolors %&gt;% filter(league == &quot;nhl&quot;) %&gt;% rename(team_id = name) %&gt;% 
  mutate(rand.color = ifelse(primary == &quot;#010101&quot;, secondary, primary))

df.beta1 &lt;- df.beta %&gt;% left_join(teamcolors1, by = c(&quot;team_id&quot; = &quot;team_id&quot;))

df.overall &lt;- ggplot(data = df.beta1, 
       aes(x = week, y = theta, 
           color = team_id, fill = team_id)) +
  geom_line(alpha = 0.5) + 
  geom_point(shape = 21) + 
  ylim(c(-0.56, 0.56)) + 
  scale_color_manual(name = NULL, values = teamcolors1$primary) + 
  scale_fill_manual(name = NULL, values = teamcolors1$secondary) + 
  guides(color = FALSE, fill = FALSE) +
  theme_bw(base_size = 14)

df.overall + 
  geom_line(data = select(df.beta1, -division), color = &quot;darkgray&quot;, alpha = 0.3) + 
  geom_line(alpha = 0.5) + 
  geom_point(shape = 21, size = 0.5, alpha = 0.8) + 
  facet_wrap(~division, ncol = 2, dir = &quot;v&quot;) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + ylab(&quot;&quot;) + xlab(&quot;Week&quot;) + 
  ggtitle(&quot;Team strength during the 2017/2018 NHL season&quot;)</code></pre>
<p><img src="/post/2018-04-09-a-state-space-model-to-evaluate-sports-team-performance_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>My favorite part about this graph is the distinction between the two Divisions in the Eastern Conference. In the Atlantic Division, Boston, Tampa, and Toronto are three top teams, and apart from the Panthers, the other teams are bottom-dwellers. Meanwhile, nearly every Metropolitan team fits somewhere between the top and bottom of the Atlantic.</p>
<p>Also impressive – check out Colorado’s slow improvement in the Central. The Avalanche started the year as the league’s third worst team (perception-wise), and are now in the playoffs.</p>
</div>
<div id="comparisons-among-teams" class="section level2">
<h2>Comparisons among teams</h2>
<p>One benefit of using a Bayesian approach is that we can more precisely interpret team strength parameters. As an example, let’s look at the posterior distributions of team strength of three NHL teams, the Penguins, Flyers, and Hurricanes. For this task, I focus on the last six weeks of the NHL regular season, to roughly reflect team strength at season’s end.</p>
<pre class="r"><code>teams &lt;- c(&quot;Carolina Hurricanes&quot;, &quot;Pittsburgh Penguins&quot;, &quot;Philadelphia Flyers&quot;)
thetas &lt;- z$theta[20:26, Teams %in% teams, ,]
colors &lt;- teamcolors1$secondary[Teams %in% teams]
team.1 &lt;- data.frame(team_id = teams[1], beta = c(thetas[,1,,]))
team.2 &lt;- data.frame(team_id = teams[2], beta = c(thetas[,2,,]))
team.3 &lt;- data.frame(team_id = teams[3], beta = c(thetas[,3,,]))

df.matchup &lt;- rbind(team.1, team.2, team.3) 
lmin &lt;- quantile(df.matchup$beta, 0.01)
umin &lt;- quantile(df.matchup$beta, 0.99)

df.matchup %&gt;% ggplot(aes(beta, fill = team_id, group = team_id)) + 
  geom_density(alpha = 0.5) + 
  scale_fill_manual(name = NULL, values = colors) + 
  annotate(&quot;text&quot;, x = lmin, y = 4, label = &quot;Hurricanes&quot;,colour = colors[1], size = 5) + 
  annotate(&quot;text&quot;, x = .19, y = 4, label = &quot;Flyers&quot;, colour = colors[2], size = 5) + 
  annotate(&quot;text&quot;, x = umin, y = 4, label = &quot;Penguins&quot;, colour = colors[3], size = 5) +
  ggtitle(&quot;Posterior draws of team strength&quot;) + 
  xlab(&quot;Team strength: log-odds scale&quot;) + ylab(&quot;Density&quot;) + 
  guides(color = FALSE, fill = FALSE) + theme_bw(14) </code></pre>
<p><img src="/post/2018-04-09-a-state-space-model-to-evaluate-sports-team-performance_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Above, the Penguins stand out as the best of the three teams. However, although it’s clear the Penguins are better than both the Flyers and the Hurricanes – note the lack of overlap in the density plots – it’s not as clear that the Flyers are better than the Hurricanes.</p>
<p>Using samples from the posterior distribution, we can be a bit more precise: there’s only about a 1 in 2000 chance that the Hurricanes are better than the Penguins, a 1 in 150 chance that the Flyers are better than the Penguins, and a 1 in 5 chance that the Hurricanes are better than the Flyers.</p>
<p>But here’s where the NHL is tricky (e.g, random).</p>
<p>Knowing that the Penguins are better than the Flyers with probability 99.4 percent does not precisely correspond to their chances of actually beating the Flyers when the two teams square off in the 1st round of the 2018 NHL playoffs. In fact, we can use our team strength estimates to sample what a 7-game playoff series could look like, and check how often each team wins. Below, I assume that the Penguins have the home advantage.</p>
<pre class="r"><code>set.seed(0)
flyers.strength &lt;- sample(team.2$beta, 7)
penguins.strength &lt;- sample(team.3$beta, 7)
home.advantage &lt;- sample(z$alpha, 7)
logit.games &lt;- penguins.strength - flyers.strength + 
  home.advantage*c(1, 1, -1, -1, 1, -1, 1)
prob.games &lt;- exp(logit.games)/(1 + exp(logit.games))
penguin.wins &lt;- rbinom(7, 1, prob = prob.games)
do.penguins.win &lt;- sum(penguin.wins) &gt;= 4
do.penguins.win</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>In the example above, the Penguins emerge victorious – congrats <a href="https://www.nhl.com/penguins/news/penguins-hire-sam-ventura-as-director-of-hockey-research/c-289961770">Sam</a>!! – but that doesn’t happen every iteration. Here’s what 10,000 series outcomes would look like:</p>
<pre class="r"><code>set.seed(0)
penguins.sim.wins &lt;- 0
for (i in 1:10000){
  flyers.strength &lt;- sample(team.2$beta, 7)
  penguins.strength &lt;- sample(team.3$beta, 7)
  home.advantage &lt;- sample(z$alpha, 7)
  logit.games &lt;- penguins.strength - flyers.strength + home.advantage*c(1, 1, -1, -1, 1, -1, 1)
  prob.games &lt;- exp(logit.games)/(1 + exp(logit.games))
  penguin.wins &lt;- rbinom(7, 1, prob = prob.games)
  do.penguins.win &lt;- sum(penguin.wins) &gt;= 4
  penguins.sim.wins &lt;- penguins.sim.wins + do.penguins.win
}
sum(penguins.sim.wins)/10000</code></pre>
<pre><code>## [1] 0.6632</code></pre>
<p>Our numbers suggest that the Penguins would beat the Flyers roughly 2 out of every 3 times they played a 7-game series. Unsurprisingly, this almost exactly matches the probability implied in sportsbook series odds, which currently price the Penguins at -225 and the Flyers at +195.</p>
<p>One last thought: how much is the home advantage worth for Pittsburgh? Tweaking the code above, the Flyers would win about 4% more often if they were the team with an extra home game. In other words, only roughly 1 in 25 series outcomes would change were the Penguins to lose their home advantage to the Flyers. This does not appear to be the answer that my Twitter followers <a href="https://twitter.com/StatsbyLopez/status/983686397818298368">expected</a>, as 1 in 25 was the least likely of four outcomes (10, 15, 20, 25).</p>
</div>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p>The above code implements a Bayesian state-space model to etimate team strength in the NHL season using betting market numbers. Though the <code>rjags</code> package is not the most user-friendly for first-time practitioners, it provides a mechanism for fitting complex models using R. The resulting team strengths are fun to graph and expore, and I encourage you to try it out yourself.</p>
<p>In future work, there are a few questions that I hope to tackle: Can our model detect if certain teams have better home advantages than others? Was there a so-called <code>Vegas flu</code>? And when did betting markets begin to pick up on it? What is the probability that any given team is better than any given other team? How did the NHLs shifting postseason structure (to a divisional format) impact postseason chances?</p>
</div>

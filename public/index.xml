<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statsbylopez on Statsbylopez</title>
    <link>/</link>
    <description>Recent content in Statsbylopez on Statsbylopez</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The impact of make-up calls is probably bigger than you think</title>
      <link>/post/the-impact-of-make-up-calls-is-probably-bigger-than-you-think/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/the-impact-of-make-up-calls-is-probably-bigger-than-you-think/</guid>
      <description>

&lt;p&gt;One of the more reliable indicators of which NHL team is likely to get the next power play has little to do with score or style of play. Instead, it&amp;rsquo;s been shown repeatedly (&lt;a href=&#34;https://fivethirtyeight.com/features/hockey-refs-are-out-to-get-you-if-they-already-got-the-other-guy/&#34; target=&#34;_blank&#34;&gt;Ex 1&lt;/a&gt;, &lt;a href=&#34;http://people.stat.sfu.ca/~tim/papers/penalty.pdf&#34; target=&#34;_blank&#34;&gt;Ex 2&lt;/a&gt;) that referees call a substantially higher number of make-up penalties than would otherwise be expected in order to maintain an overall even number of violations on each team. Call it a &lt;a href=&#34;https://creativematter.skidmore.edu/cgi/viewcontent.cgi?article=1004&amp;amp;context=math_fac_schol&#34; target=&#34;_blank&#34;&gt;&lt;em&gt;biased impartiality&lt;/em&gt;&lt;/a&gt; &amp;ndash; in order to appear impartial by game&amp;rsquo;s end, ref&amp;rsquo;s let previous decisions drive future ones.&lt;/p&gt;

&lt;p&gt;A common line of reasoning behind call reversals is that referees would prefer to $not$ be part of the final narrative as to why a particular team won or lost. If each team has a relatively similar number of power plays, media and fans clamoring that one team was favored would have less support. Turns out, however, that by evening up penalty calls, hockey ref&amp;rsquo;s are impacting the same game narratives that they are trying to avoid being a part of. In this post, I&amp;rsquo;ll both confirm the existance of make-up calls and extend a similar analysis to look at the impact of make-up calls on game outcomes.&lt;/p&gt;

&lt;h2 id=&#34;the-make-up-call&#34;&gt;The make-up call&lt;/h2&gt;

&lt;p&gt;Claiming that a call in any sport is due to anything besides an unbiased referee assessment is a non-trivial task. Fortunately, hockey boasts several settings that make looking for make-up calls somewhat feasible. Game&amp;rsquo;s are often tied, and looking at penalties in tied-game states can avoid results being impacted by changes in style of play due to the score. Moreover, with an average of about eight minors a game &amp;ndash; most of them judgement calls &amp;ndash;  there&amp;rsquo;s a large enough sample size within each game on which to evaluate ref choices.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an initial chart comparing the penalty differential between each team at the end of the first period (y-axis, where positive means more penalties) to penalty differential over the remainder of the game (shown in the darkness and color of the grid).&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; The x-axis corresponds to the home team&amp;rsquo;s estimated pre-game win probability, calculated using odds implied by betting markets (you can get that data &lt;a href=&#34;https://github.com/bigfour/competitiveness/blob/master/data/bigfour_public.rda&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;). Accounting for relative team talent is potentially important, as its a variable that&amp;rsquo;s quite possibly linked to penalty calls and team aggressiveness. Only games that were tied at the end of the first period are included in this chart &amp;ndash; the data goes from the 05-06 to 15-16 regular seasons.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/makeupF1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;When home teams have two more infractions than their opponent at the end of the first period, they average roughly 0.8 fewer infractions the rest of the game. Alternatively, when home teams have two fewer penalties at the end of the first, they average about 0.5 more violations in periods 2 and 3. The difference between having more and fewer penalties in tied games is quite significant from a statistical perspective. Of course, if you had read a few of the links above, you probably would have guessed that there would be this type of impact. But the effect size (as much as 1.3 penalties), as well as the shading of the chart above, seemed noteworthy.&lt;/p&gt;

&lt;h2 id=&#34;the-impact-of-the-make-up-call&#34;&gt;The impact of the make-up call&lt;/h2&gt;

&lt;p&gt;Make-up calls are all well and good until some team loses a game because of it.&lt;/p&gt;

&lt;p&gt;To check how future games are impacted by make-up calls, I used a chart similar to the one shown above. In this one, however, shading reflects the percent of games eventually won by the home team.&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;/img/makeupF2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this version, the shading is reversed &amp;ndash; more first period penalties are linked to an increased win rate, just as fewer penalties are linked to a decreased win rate. Again, remember that we&amp;rsquo;re only looking at tied games, and we&amp;rsquo;re accounting for how good each team is!&lt;/p&gt;

&lt;p&gt;Altogether, when the game is expected to be a relative toss-up, the difference between having two more first period penalties and two fewer first period penalties is about 7 or 8 percentage points in terms of the home team&amp;rsquo;s chances. The effect is a bit larger when the home team is not expected to win, with differences between fewer and more first period worth an estimated 10 percentage points.&lt;/p&gt;

&lt;p&gt;While this may seem like a relatively minor change, the fact that there&amp;rsquo;s $any$ change in win rate based on prior penalties is curious.
Additionally, we may be underestimating the impact of make-up calls &amp;ndash; if a team had more first period penalties, it would have likewise been more likely to start the second period on a penalty kill, a quirk that I did not account for above. Further, this isn&amp;rsquo;t a peculiar set of games  &amp;ndash; about a third of NHL games end the first period tied. Finally, although it&amp;rsquo;d require further assumptions with respect to playing style, it&amp;rsquo;s also likely that make-up calls have an impact on games that aren&amp;rsquo;t tied.&lt;/p&gt;

&lt;p&gt;One limitation of this post is that, in using observational data, it is feasible that there&amp;rsquo;s something else responsible for the link between first period penalty differential and game outcomes. One possible alternative is that teams that have taken penalties suddenly feel the need to be more aggressive, which then leads to more natural reversals masquerading as make-up calls. However, in using tied games, I can&amp;rsquo;t imagine that the revenge factor looms too large. Further, in &lt;a href=&#34;https://creativematter.skidmore.edu/cgi/viewcontent.cgi?article=1004&amp;amp;context=math_fac_schol&#34; target=&#34;_blank&#34;&gt;previous work&lt;/a&gt;, penalty reversals were, if anything, higher in the postseason, where there is almost no desire for revenge (at least via penalties).&lt;/p&gt;

&lt;p&gt;If you are curious about the coding for the project, I used play-by-play data via the now archived &lt;a href=&#34;https://cran.r-project.org/web/packages/nhlscrapr/index.html&#34; target=&#34;_blank&#34;&gt;nhlscrapr&lt;/a&gt; package in R. Matching minors, as well as all major penalties, were dropped. The code for all figures, models, and numbers is &lt;a href=&#34;https://github.com/statsbylopez/BlogPosts/blob/master/NHL_predict_penaltydiff.R&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;I used a generalized additive model (GAM) of penalty differential as a factor of both home team win probability and first period penalty differential. In this and the example below, first period penalty differential was a significant predictor. GAMs make sense in this and other examples, as the true model fit with penalty outcomes is unknown.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;Same model as above, now with a binary outcome.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;^&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>On the risks of categorizing a continuous variable (with an application to baseball data)</title>
      <link>/post/on-the-risks-of-categorizing-a-continuous-variable/</link>
      <pubDate>Wed, 07 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/on-the-risks-of-categorizing-a-continuous-variable/</guid>
      <description>&lt;div id=&#34;to-err-is-to-human&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;To err is to human&lt;/h3&gt;
&lt;p&gt;In the third inning during a contest a few weeks back between the Nationals and Cubs, Washington’s Brian Goodwin hit a line drive to left field with two outs and a runner on third. Despite an initial pause, Chicago’s Kyle Schwarber ran in and attempted to field the ball around his knees.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;/img/Kyle.gif&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;Ruled an error on Schwarber, the play gave the a Nationals run in an eventual 9-4 win. This struck me as an odd ruling. Schwarber could have easily stood still, retrieved the ball on a hop, and not been given an error. Instead, by trying to field the hard hit ball and missing, he was punished. Note that Goodwin did not reach second after Schwarber’s mishap.&lt;/p&gt;
&lt;p&gt;Intracacies of the baseball rulebook are out of my realm of expertise, but that specific play got me thinking about what goes into decisions to reward an error. Primarily – is the difficulty of the play (including the exit velocity of the hit) taken into account? Fielding a sharp ground ball or line drive, no matter where its hit, would seem excessively more difficult than fielding a dribbler or pop fly. Alternatively, one could argue that its the slowest ground balls that are the most problematic, given that a fielder may need to rush his throw.&lt;/p&gt;
&lt;p&gt;The point of this post will be to identify a few predictors of error rates, starting with a sidebar about categorizing continuous variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exit-velocity-is-so-good-..-it-predicts-higher-and-lower-error-rates.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exit velocity is so good .. it predicts higher &lt;em&gt;and&lt;/em&gt; lower error rates.&lt;/h3&gt;
&lt;p&gt;Using the last two seasons of Statcast data, and with a huge hat tip to Bill Petti’s &lt;a href=&#34;http://billpetti.github.io/baseballr/&#34;&gt;baseballr&lt;/a&gt; package, I grabbed all potential putouts (any play ruled an out, error, sac fly, bunt, etc). The Statcast data is super useful, as for games since 2015, it contains exit velocity and launch angle for each ball in play.&lt;/p&gt;
&lt;p&gt;My first interest lies in whether or not exit velocity is linked to error chances. One popular strategy (both in and outside of sports analytics) is to categorize data. In other words, group balls in play together, bin hits with similar velocities, and check for the frequency of errors within each bin. That was my first step with the Statcast data. But because I was unsure what categories to use, I tried two different sets: (i) 70 mph or less, 70-85, 85 or more and (ii) 80 or less, 80-95, 95 or more. Each was roughly meant to align with softly hit, medium hit, and sharply hit balls, and each contained several thousand balls in play.&lt;/p&gt;
&lt;p&gt;Here’s a chart showing the fraction of plays resulting in an error in each bin. The point in each graph is the average number of errors on all balls in play for each bin.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-03-07-on-the-risks-of-categorizing-a-continuous-variable_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Your eyes are not deceiving you.&lt;/p&gt;
&lt;p&gt;On the left graph, there’s a drop in error rate with increased exit velocity – on the right, there’s an increase in the rate of errors. That is, with identical data and only a slight shift in groupings, you could make either claim and feel justified. Errors appear to both increase and decrease with harder hit balls, and both contrasts are statistically significant (those are 95% intervals included with each point).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;so-which-is-it&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;So which is it?&lt;/h3&gt;
&lt;p&gt;In fairness to the above analysis, both charts are correct. In unfairness to the above, such analysis is often problematic, and its no accident that the findings conflict.&lt;/p&gt;
&lt;p&gt;Specifically, categorizing a continuous variable and looking within each category or bin can lead to a host of statistical problems. For an excellent overview, see a Vanderbilt biostat write-up &lt;a href=&#34;http://biostat.mc.vanderbilt.edu/wiki/Main/CatContinuous&#34;&gt;here&lt;/a&gt;, or read a more thorough paper by Caroline Bennette and Andrew Vickers &lt;a href=&#34;https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-12-21&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Two problems discussed above specifically come into play with respect to our binning above.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Categorization assumes that there is a discontinuity in response (error rates) as interval boundaries are crossed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Categorization assumes that the relationship between the predictor (exit velocity) and the response (error rates) is flat within intervals.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Indeed, error rates have a slightly more complicated relationship with exit velocity than can be explained by intervals, and when diving deeper, it’s evident that there’s no natural discontinuity in the rates of errors that we could even try to use.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-alternative-strategy-for-measuring-error-rates.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;An alternative strategy for measuring error rates.&lt;/h3&gt;
&lt;p&gt;Instead of binning, a more appropriate technique would involve modeling the rates of errors given exit velocity.&lt;/p&gt;
&lt;p&gt;Of course, in light of the above charts, the link between error rates and exit velocity may be complex, and traditional logistic regression may not be sufficient. Instead, I used a generalized additive model (GAM) that included smoothed terms for both exit velocity and launch angle. GAMs can be great with sports data – they are easy to implement, explicitly include cross-validation as part of the fitting process, and don’t require an exact model specification. Given that we don’t know the best way to specify a model of errors given launch speed, GAMs are a natural fit.&lt;/p&gt;
&lt;p&gt;One final plus? GAMs also make for nice visualizations, something that every sports analyst should always be working on. If you want to read more about GAMs, start with the Stitch Fix &lt;a href=&#34;http://multithreaded.stitchfix.com/blog/2015/07/30/gam/&#34;&gt;tutorial&lt;/a&gt;, or I’ll shamelessly promote my work on NFL referees (&lt;a href=&#34;https://statsbylopez.files.wordpress.com/2013/08/lopez-2016-economic_inquiry.pdf&#34;&gt;link&lt;/a&gt;) and Brian’s work on MLB umpires (&lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1002/mde.2630/abstract&#34;&gt;link&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Here’s a chart showing the estimated error rate given exit velocity (x axis) and launch angle (y axis). Darker shades are linked to higher error rates.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: nlme&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Attaching package: &amp;#39;nlme&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## The following object is masked from &amp;#39;package:dplyr&amp;#39;:
## 
##     collapse&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## This is mgcv 1.8-22. For overview type &amp;#39;help(&amp;quot;mgcv-package&amp;quot;)&amp;#39;.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-03-07-on-the-risks-of-categorizing-a-continuous-variable_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Turns out, there’s an obvious driver of the error rate weirdness – sacrifices!&lt;/p&gt;
&lt;p&gt;A few thousand of our plays feature balls hit at roughly 40 mph going (almost) directly into the ground. While not all of these plays are attempted bunts, many appear to be (according to the Statcast play by play descriptions). Turns out, bunts are linked to high error rates (as high as 14%), likely on account of how quickly the pitcher and infielders need to react.&lt;/p&gt;
&lt;p&gt;Returning to our original question, there does appear to be a slight increase in error rates with increased exit velocity after discarding bunt attempts. Although balls hit between 50 and 90 mph all yield roughly have the same chances of an error (somewhere around 2%) – error chances increase with the hardest hit balls. With exit velocities of 110 mph or higher, for example, our model expects error rates at several launch angles to be more than 5%.&lt;/p&gt;
&lt;p&gt;Note that one downside of the chart is that we don’t get to see how many balls are hit at each launch speed and angle. For example, the dark right corner of the chart only includes a few fieldable plays, and these estimates likely come with substantial error. However, we can crosscheck some of the dark spots using the actual data. Sure enough, balls hit with an exit velocity of 100 mph or higher within +/5 degrees of 0 yield an error rate of 4.9% (there were about 5400 such instances). Hit it 105 mph or harder in that same zone, and the error rate jumps to 6%.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-the-take-home&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What’s the take home?&lt;/h3&gt;
&lt;p&gt;From a statistical perspective, hopefully you can recognize both the dangers of categorizing continuous data, as well as the attractive features offered by a GAM (and if you want to try a GAM yourself – the code is up &lt;a href=&#34;https://github.com/statsbylopez/statsbylopez.github.io&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;From a baseball perspective, the hardest hit balls do increase error rates. Additionally, with my intuition being that errors are often discarded from the perspective of analyzing hitter talent, this type of error creation could be worth thinking more about. In addition to a side benefit of someone who hits the ball as hard as Aaron Judge or Giancarlo Stanton, having good, capable bunters &lt;em&gt;could&lt;/em&gt; actually be undervalued. Putting down a sacrifice is generally not considered worth it (trading an out for moving up a base), but with error rates as high as 14%, there may be more to the story.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>NESSIS 2017</title>
      <link>/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://sourcethemes.com/academic/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
